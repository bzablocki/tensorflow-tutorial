{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Exercise \n",
    "\n",
    "California Housing Data\n",
    "\n",
    "This data set contains information about all the block groups in California from the 1990 Census. In this sample a block group on average includes 1425.5 individuals living in a geographically compact area. \n",
    "\n",
    "The task is to aproximate the median house value of each block from the values of the rest of the variables. \n",
    "\n",
    " It has been obtained from the LIACC repository. The original page where the data set can be found is: http://www.liaad.up.pt/~ltorgo/Regression/DataSets.html.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The Features:\n",
    " \n",
    "* housingMedianAge: continuous. \n",
    "* totalRooms: continuous. \n",
    "* totalBedrooms: continuous. \n",
    "* population: continuous. \n",
    "* households: continuous. \n",
    "* medianIncome: continuous. \n",
    "* medianHouseValue: continuous. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the cal_housing_clean.csv file with pandas. Separate it into a training (70%) and testing set(30%).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('cal_housing_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  medianHouseValue  \n",
       "0        8.3252          452600.0  \n",
       "1        8.3014          358500.0  \n",
       "2        7.2574          352100.0  \n",
       "3        5.6431          341300.0  \n",
       "4        3.8462          342200.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "      <th>medianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.639486</td>\n",
       "      <td>2635.763081</td>\n",
       "      <td>537.898014</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>499.539680</td>\n",
       "      <td>3.870671</td>\n",
       "      <td>206855.816909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.585558</td>\n",
       "      <td>2181.615252</td>\n",
       "      <td>421.247906</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>382.329753</td>\n",
       "      <td>1.899822</td>\n",
       "      <td>115395.615874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.499900</td>\n",
       "      <td>14999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1447.750000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>2.563400</td>\n",
       "      <td>119600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>435.000000</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>409.000000</td>\n",
       "      <td>3.534800</td>\n",
       "      <td>179700.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>3148.000000</td>\n",
       "      <td>647.000000</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>4.743250</td>\n",
       "      <td>264725.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>39320.000000</td>\n",
       "      <td>6445.000000</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>6082.000000</td>\n",
       "      <td>15.000100</td>\n",
       "      <td>500001.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       housingMedianAge    totalRooms  totalBedrooms    population  \\\n",
       "count      20640.000000  20640.000000   20640.000000  20640.000000   \n",
       "mean          28.639486   2635.763081     537.898014   1425.476744   \n",
       "std           12.585558   2181.615252     421.247906   1132.462122   \n",
       "min            1.000000      2.000000       1.000000      3.000000   \n",
       "25%           18.000000   1447.750000     295.000000    787.000000   \n",
       "50%           29.000000   2127.000000     435.000000   1166.000000   \n",
       "75%           37.000000   3148.000000     647.000000   1725.000000   \n",
       "max           52.000000  39320.000000    6445.000000  35682.000000   \n",
       "\n",
       "         households  medianIncome  medianHouseValue  \n",
       "count  20640.000000  20640.000000      20640.000000  \n",
       "mean     499.539680      3.870671     206855.816909  \n",
       "std      382.329753      1.899822     115395.615874  \n",
       "min        1.000000      0.499900      14999.000000  \n",
       "25%      280.000000      2.563400     119600.000000  \n",
       "50%      409.000000      3.534800     179700.000000  \n",
       "75%      605.000000      4.743250     264725.000000  \n",
       "max     6082.000000     15.000100     500001.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>housingMedianAge</th>\n",
       "      <th>totalRooms</th>\n",
       "      <th>totalBedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>medianIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   housingMedianAge  totalRooms  totalBedrooms  population  households  \\\n",
       "0              41.0       880.0          129.0       322.0       126.0   \n",
       "1              21.0      7099.0         1106.0      2401.0      1138.0   \n",
       "2              52.0      1467.0          190.0       496.0       177.0   \n",
       "3              52.0      1274.0          235.0       558.0       219.0   \n",
       "4              52.0      1627.0          280.0       565.0       259.0   \n",
       "\n",
       "   medianIncome  \n",
       "0        8.3252  \n",
       "1        8.3014  \n",
       "2        7.2574  \n",
       "3        5.6431  \n",
       "4        3.8462  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data = data.drop('medianHouseValue', axis=1)\n",
    "y_label = data['medianHouseValue']\n",
    "X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    452600.0\n",
       "1    358500.0\n",
       "2    352100.0\n",
       "3    341300.0\n",
       "4    342200.0\n",
       "Name: medianHouseValue, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_label, test_size=0.3, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the Feature Data\n",
    "\n",
    "** Use sklearn preprocessing to create a MinMaxScaler for the feature data. Fit this scaler only to the training data. Then use it to transform X_test and X_train. Then use the scaled X_test and X_train along with pd.Dataframe to re-create two dataframes of scaled data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_pd = pd.DataFrame(data = scaler.transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_test_pd = pd.DataFrame(data = scaler.transform(X_test), columns=X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Feature Columns\n",
    "\n",
    "** Create the necessary tf.feature_column objects for the estimator. They should all be trated as continuous numeric_columns. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols_loop = [tf.feature_column.numeric_column(str(col)) for col in X_train_pd.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column('housingMedianAge')\n",
    "rooms = tf.feature_column.numeric_column('totalRooms')\n",
    "bedrooms = tf.feature_column.numeric_column('totalBedrooms')\n",
    "pop = tf.feature_column.numeric_column('population')\n",
    "households = tf.feature_column.numeric_column('households')\n",
    "income = tf.feature_column.numeric_column('medianIncome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "feat_cols = [ age,rooms,bedrooms,pop,households,income]\n",
    "print(feat_cols_loop == feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x24929138908>]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAD8CAYAAACLrvgBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nChoiIpLY/wdnXCtcKhoEFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x249290da3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X_train_pd['housingMedianAge'].sample(150, random_state=101), y_train.sample(150, random_state=101), '*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the input function for the estimator object. (play around with batch_size and num_epochs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_fn = tf.estimator.inputs.pandas_input_fn(x=X_train_pd, y=y_train, batch_size=10, \n",
    "                                               num_epochs=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create the estimator model. Use a DNNRegressor. Play around with the hidden units! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\motos\\AppData\\Local\\Temp\\tmpm27qozpz\n",
      "INFO:tensorflow:Using config: {'_save_summary_steps': 100, '_save_checkpoints_steps': None, '_tf_random_seed': 1, '_log_step_count_steps': 100, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_model_dir': 'C:\\\\Users\\\\motos\\\\AppData\\\\Local\\\\Temp\\\\tmpm27qozpz', '_session_config': None}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.DNNRegressor(feature_columns=feat_cols, hidden_units=[6,4,4])\n",
    "# model = tf.estimator.LinearRegressor(feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ** Train the model for ~1,000 steps. (Later come back to this and train it for more and check for improvement) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\motos\\AppData\\Local\\Temp\\tmpm27qozpz\\model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 3.46295e+11\n",
      "INFO:tensorflow:global_step/sec: 520.447\n",
      "INFO:tensorflow:step = 101, loss = 5.73541e+11 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 552.951\n",
      "INFO:tensorflow:step = 201, loss = 5.07337e+11 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 505.986\n",
      "INFO:tensorflow:step = 301, loss = 1.50524e+11 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 540.088\n",
      "INFO:tensorflow:step = 401, loss = 5.07469e+11 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.911\n",
      "INFO:tensorflow:step = 501, loss = 6.18161e+11 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.755\n",
      "INFO:tensorflow:step = 601, loss = 3.63343e+11 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 547.461\n",
      "INFO:tensorflow:step = 701, loss = 4.36822e+11 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.298\n",
      "INFO:tensorflow:step = 801, loss = 7.87793e+11 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.186\n",
      "INFO:tensorflow:step = 901, loss = 2.27053e+11 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.325\n",
      "INFO:tensorflow:step = 1001, loss = 4.3691e+11 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.976\n",
      "INFO:tensorflow:step = 1101, loss = 2.12651e+11 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.978\n",
      "INFO:tensorflow:step = 1201, loss = 6.65095e+11 (0.211 sec)\n",
      "INFO:tensorflow:global_step/sec: 548.967\n",
      "INFO:tensorflow:step = 1301, loss = 4.77124e+11 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 555.046\n",
      "INFO:tensorflow:step = 1401, loss = 1.71573e+11 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.015\n",
      "INFO:tensorflow:step = 1501, loss = 3.62867e+11 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 535.752\n",
      "INFO:tensorflow:step = 1601, loss = 2.37572e+11 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 574.13\n",
      "INFO:tensorflow:step = 1701, loss = 2.14065e+11 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.132\n",
      "INFO:tensorflow:step = 1801, loss = 5.13405e+10 (0.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.909\n",
      "INFO:tensorflow:step = 1901, loss = 3.23627e+11 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.214\n",
      "INFO:tensorflow:step = 2001, loss = 3.69442e+11 (0.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 551.989\n",
      "INFO:tensorflow:step = 2101, loss = 1.1595e+11 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.486\n",
      "INFO:tensorflow:step = 2201, loss = 2.01204e+11 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.904\n",
      "INFO:tensorflow:step = 2301, loss = 9.70869e+10 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 513.777\n",
      "INFO:tensorflow:step = 2401, loss = 6.08493e+10 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 561.265\n",
      "INFO:tensorflow:step = 2501, loss = 1.82208e+11 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.012\n",
      "INFO:tensorflow:step = 2601, loss = 1.62735e+11 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 535.754\n",
      "INFO:tensorflow:step = 2701, loss = 1.27189e+11 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 564.43\n",
      "INFO:tensorflow:step = 2801, loss = 8.56944e+10 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.908\n",
      "INFO:tensorflow:step = 2901, loss = 1.07382e+11 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.095\n",
      "INFO:tensorflow:step = 3001, loss = 8.44499e+10 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.163\n",
      "INFO:tensorflow:step = 3101, loss = 1.34056e+11 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.294\n",
      "INFO:tensorflow:step = 3201, loss = 1.76424e+11 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 519.098\n",
      "INFO:tensorflow:step = 3301, loss = 6.9321e+10 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.754\n",
      "INFO:tensorflow:step = 3401, loss = 1.63681e+11 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 467.069\n",
      "INFO:tensorflow:step = 3501, loss = 2.35387e+11 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 543.013\n",
      "INFO:tensorflow:step = 3601, loss = 8.38713e+10 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.737\n",
      "INFO:tensorflow:step = 3701, loss = 6.29452e+10 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 550.489\n",
      "INFO:tensorflow:step = 3801, loss = 1.57829e+11 (0.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.158\n",
      "INFO:tensorflow:step = 3901, loss = 7.73617e+10 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.904\n",
      "INFO:tensorflow:step = 4001, loss = 5.39645e+10 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 527.295\n",
      "INFO:tensorflow:step = 4101, loss = 5.93635e+10 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.444\n",
      "INFO:tensorflow:step = 4201, loss = 8.66591e+10 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 515.095\n",
      "INFO:tensorflow:step = 4301, loss = 1.28959e+11 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.571\n",
      "INFO:tensorflow:step = 4401, loss = 3.81669e+10 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 524.532\n",
      "INFO:tensorflow:step = 4501, loss = 7.20156e+10 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 489.906\n",
      "INFO:tensorflow:step = 4601, loss = 1.014e+11 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 503.448\n",
      "INFO:tensorflow:step = 4701, loss = 1.13275e+11 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 559.696\n",
      "INFO:tensorflow:step = 4801, loss = 2.91755e+10 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 511.153\n",
      "INFO:tensorflow:step = 4901, loss = 1.43028e+11 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 504.713\n",
      "INFO:tensorflow:step = 5001, loss = 1.38424e+11 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.755\n",
      "INFO:tensorflow:step = 5101, loss = 1.24687e+11 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 508.558\n",
      "INFO:tensorflow:step = 5201, loss = 7.427e+10 (0.197 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.462\n",
      "INFO:tensorflow:step = 5301, loss = 7.96673e+10 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 556.587\n",
      "INFO:tensorflow:step = 5401, loss = 6.93415e+10 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 437.493\n",
      "INFO:tensorflow:step = 5501, loss = 1.59697e+11 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.588\n",
      "INFO:tensorflow:step = 5601, loss = 9.59507e+10 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.645\n",
      "INFO:tensorflow:step = 5701, loss = 1.10399e+11 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 471.464\n",
      "INFO:tensorflow:step = 5801, loss = 1.11e+11 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 535.752\n",
      "INFO:tensorflow:step = 5901, loss = 1.04351e+11 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.757\n",
      "INFO:tensorflow:step = 6001, loss = 9.41543e+10 (0.194 sec)\n",
      "INFO:tensorflow:global_step/sec: 392.117\n",
      "INFO:tensorflow:step = 6101, loss = 7.42762e+10 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.191\n",
      "INFO:tensorflow:step = 6201, loss = 1.09375e+11 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 494.746\n",
      "INFO:tensorflow:step = 6301, loss = 1.15157e+11 (0.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 528.683\n",
      "INFO:tensorflow:step = 6401, loss = 1.14157e+11 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.902\n",
      "INFO:tensorflow:step = 6501, loss = 1.42962e+11 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 564.431\n",
      "INFO:tensorflow:step = 6601, loss = 9.04948e+10 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.562\n",
      "INFO:tensorflow:step = 6701, loss = 9.70409e+10 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.65\n",
      "INFO:tensorflow:step = 6801, loss = 1.07366e+11 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 374.525\n",
      "INFO:tensorflow:step = 6901, loss = 5.95796e+10 (0.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 363.653\n",
      "INFO:tensorflow:step = 7001, loss = 6.37455e+10 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.9\n",
      "INFO:tensorflow:step = 7101, loss = 1.2845e+11 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.57\n",
      "INFO:tensorflow:step = 7201, loss = 1.28056e+11 (0.312 sec)\n",
      "INFO:tensorflow:global_step/sec: 375.227\n",
      "INFO:tensorflow:step = 7301, loss = 7.25744e+10 (0.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.462\n",
      "INFO:tensorflow:step = 7401, loss = 6.31037e+10 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 520.446\n",
      "INFO:tensorflow:step = 7501, loss = 7.12438e+10 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.902\n",
      "INFO:tensorflow:step = 7601, loss = 7.63003e+10 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.491\n",
      "INFO:tensorflow:step = 7701, loss = 1.26108e+11 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 519.096\n",
      "INFO:tensorflow:step = 7801, loss = 5.89801e+10 (0.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 548.966\n",
      "INFO:tensorflow:step = 7901, loss = 8.03944e+10 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 545.972\n",
      "INFO:tensorflow:step = 8001, loss = 1.68302e+11 (0.183 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 555.045\n",
      "INFO:tensorflow:step = 8101, loss = 5.01931e+10 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 580.789\n",
      "INFO:tensorflow:step = 8201, loss = 5.27177e+10 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 551.988\n",
      "INFO:tensorflow:step = 8301, loss = 2.23705e+10 (0.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 572.489\n",
      "INFO:tensorflow:step = 8401, loss = 1.203e+11 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.459\n",
      "INFO:tensorflow:step = 8501, loss = 6.88318e+10 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.726\n",
      "INFO:tensorflow:step = 8601, loss = 1.18717e+11 (0.239 sec)\n",
      "INFO:tensorflow:global_step/sec: 582.474\n",
      "INFO:tensorflow:step = 8701, loss = 1.35328e+11 (0.170 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.459\n",
      "INFO:tensorflow:step = 8801, loss = 3.36164e+10 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 567.622\n",
      "INFO:tensorflow:step = 8901, loss = 8.08927e+10 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 569.24\n",
      "INFO:tensorflow:step = 9001, loss = 2.06688e+10 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 545.975\n",
      "INFO:tensorflow:step = 9101, loss = 9.60836e+10 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 439.411\n",
      "INFO:tensorflow:step = 9201, loss = 1.01045e+11 (0.234 sec)\n",
      "INFO:tensorflow:global_step/sec: 398.353\n",
      "INFO:tensorflow:step = 9301, loss = 6.08448e+10 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.631\n",
      "INFO:tensorflow:step = 9401, loss = 1.14177e+11 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 534.325\n",
      "INFO:tensorflow:step = 9501, loss = 1.49362e+11 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 483.988\n",
      "INFO:tensorflow:step = 9601, loss = 1.92554e+11 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.59\n",
      "INFO:tensorflow:step = 9701, loss = 1.14992e+11 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 504.715\n",
      "INFO:tensorflow:step = 9801, loss = 8.02407e+10 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.61\n",
      "INFO:tensorflow:step = 9901, loss = 1.62116e+11 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 530.084\n",
      "INFO:tensorflow:step = 10001, loss = 1.40864e+11 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.317\n",
      "INFO:tensorflow:step = 10101, loss = 9.80386e+10 (0.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.186\n",
      "INFO:tensorflow:step = 10201, loss = 1.90393e+11 (0.195 sec)\n",
      "INFO:tensorflow:global_step/sec: 388.317\n",
      "INFO:tensorflow:step = 10301, loss = 9.14292e+10 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.26\n",
      "INFO:tensorflow:step = 10401, loss = 3.70313e+10 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 463.824\n",
      "INFO:tensorflow:step = 10501, loss = 7.79106e+10 (0.212 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.324\n",
      "INFO:tensorflow:step = 10601, loss = 1.18281e+11 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 535.753\n",
      "INFO:tensorflow:step = 10701, loss = 1.52419e+11 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 499.682\n",
      "INFO:tensorflow:step = 10801, loss = 4.82457e+10 (0.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.166\n",
      "INFO:tensorflow:step = 10901, loss = 4.13154e+10 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 540.085\n",
      "INFO:tensorflow:step = 11001, loss = 1.18815e+11 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 559.697\n",
      "INFO:tensorflow:step = 11101, loss = 6.66638e+10 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 478.214\n",
      "INFO:tensorflow:step = 11201, loss = 1.66879e+11 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 344.873\n",
      "INFO:tensorflow:step = 11301, loss = 9.13943e+10 (0.284 sec)\n",
      "INFO:tensorflow:global_step/sec: 530.085\n",
      "INFO:tensorflow:step = 11401, loss = 6.06859e+10 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.632\n",
      "INFO:tensorflow:step = 11501, loss = 1.97234e+11 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 460.623\n",
      "INFO:tensorflow:step = 11601, loss = 1.05435e+11 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 372.44\n",
      "INFO:tensorflow:step = 11701, loss = 7.72821e+10 (0.260 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.757\n",
      "INFO:tensorflow:step = 11801, loss = 6.3483e+10 (0.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 532.904\n",
      "INFO:tensorflow:step = 11901, loss = 9.92205e+10 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 440.374\n",
      "INFO:tensorflow:step = 12001, loss = 8.96161e+10 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 509.855\n",
      "INFO:tensorflow:step = 12101, loss = 1.5404e+11 (0.201 sec)\n",
      "INFO:tensorflow:global_step/sec: 313.079\n",
      "INFO:tensorflow:step = 12201, loss = 5.20922e+10 (0.317 sec)\n",
      "INFO:tensorflow:global_step/sec: 452.308\n",
      "INFO:tensorflow:step = 12301, loss = 8.66463e+10 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 553.515\n",
      "INFO:tensorflow:step = 12401, loss = 1.09595e+11 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 535.754\n",
      "INFO:tensorflow:step = 12501, loss = 6.86941e+10 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 535.754\n",
      "INFO:tensorflow:step = 12601, loss = 9.45519e+10 (0.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 535.752\n",
      "INFO:tensorflow:step = 12701, loss = 5.26208e+10 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 495.968\n",
      "INFO:tensorflow:step = 12801, loss = 9.10103e+10 (0.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.121\n",
      "INFO:tensorflow:step = 12901, loss = 9.29457e+10 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.85\n",
      "INFO:tensorflow:step = 13001, loss = 1.02928e+11 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.839\n",
      "INFO:tensorflow:step = 13101, loss = 8.4201e+10 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 328.478\n",
      "INFO:tensorflow:step = 13201, loss = 1.12041e+11 (0.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 335.631\n",
      "INFO:tensorflow:step = 13301, loss = 6.96656e+10 (0.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 393.658\n",
      "INFO:tensorflow:step = 13401, loss = 1.59953e+11 (0.254 sec)\n",
      "INFO:tensorflow:global_step/sec: 364.312\n",
      "INFO:tensorflow:step = 13501, loss = 7.50186e+10 (0.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.854\n",
      "INFO:tensorflow:step = 13601, loss = 7.06113e+10 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 465.98\n",
      "INFO:tensorflow:step = 13701, loss = 3.89883e+10 (0.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.686\n",
      "INFO:tensorflow:step = 13801, loss = 9.58719e+10 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 498.438\n",
      "INFO:tensorflow:step = 13901, loss = 7.34002e+10 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 582.473\n",
      "INFO:tensorflow:step = 14001, loss = 3.1811e+10 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.357\n",
      "INFO:tensorflow:step = 14101, loss = 1.04268e+11 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 556.587\n",
      "INFO:tensorflow:step = 14201, loss = 8.0004e+10 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 537.189\n",
      "INFO:tensorflow:step = 14301, loss = 1.31616e+11 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 703.056\n",
      "INFO:tensorflow:step = 14401, loss = 1.12298e+11 (0.141 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 14448 into C:\\Users\\motos\\AppData\\Local\\Temp\\tmpm27qozpz\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8.28932e+10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x1c4f07d80b8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(input_fn=input_fn, steps=25000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a prediction input function and then use the .predict method off your estimator model to create a list or predictions on your test data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\motos\\AppData\\Local\\Temp\\tmpm27qozpz\\model.ckpt-14448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.2095711674074816e+17"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_input_fn = tf.estimator.inputs.pandas_input_fn(x=X_test, shuffle=False, num_epochs=1, batch_size=10)\n",
    "\n",
    "predictions = list(model.predict(input_fn=predict_input_fn))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "final_preds = [pred['predictions'][0] for pred in predictions]\n",
    "mean_squared_error(y_test, final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\motos\\AppData\\Local\\Temp\\tmp7r5nv1e7\\model.ckpt-50000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Calculate the RMSE. You should be able to get around 100,000 RMSE (remember that this is in the same units as the label.) Do this manually or use [sklearn.metrics](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517683839.78122622"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-10-26-20:12:22\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\motos\\AppData\\Local\\Temp\\tmp7ohrneth\\model.ckpt-2445\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-26-20:12:24\n",
      "INFO:tensorflow:Saving dict for global step 2445: average_loss = 1.11729e+10, global_step = 2445, loss = 1.11714e+11\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'average_loss': 1.1172898e+10, 'global_step': 2445, 'loss': 1.1171352e+11}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
